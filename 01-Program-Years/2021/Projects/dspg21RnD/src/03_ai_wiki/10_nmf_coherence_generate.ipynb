{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use BII, 20 cores, 3 hours, 100 Ram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import time\n",
    "\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:Input a dataframe that are ai related abstracts, need variables: final_frqwds_removed\n",
    "#abstracts = pd.read_csv(r'/home/zz3hs/git/dspg21RnD/data/dspg21RnD/bert_ai_abstracts_2.csv') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ['direct', 'identification', 'basic', 'apply',...\n",
       "1       ['previous', 'grant', 'award', 'ies', 'nationa...\n",
       "2       ['previous', 'grant', 'award', 'ies', 'graspab...\n",
       "3       ['team', 'prototype', 'web', 'coding', 'progre...\n",
       "4       ['prototype', 'science', 'quest', 'science', '...\n",
       "                              ...                        \n",
       "7653    ['artificial_intelligence', 'fuel', 'recent', ...\n",
       "7654    ['frontier', 'trustworthy', 'machine_learning'...\n",
       "7655    ['predictive', 'underdamped', 'pneumatically_a...\n",
       "7656    ['order', 'optimal', 'value', 'decision', 'ani...\n",
       "7657    ['american_indian', 'science', 'engineering', ...\n",
       "Name: final_frqwds_removed, Length: 7658, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts[\"final_frqwds_removed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option(\"display.max_colwidth\", -1)\n",
    "#abstracts[abstracts[\"cosine_similarity_score\"] >0.55].ABSTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abstracts[abstracts[\"cosine_similarity_score\"]  <0.41].ABSTRACT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coherence Model to find the optimal number of topics for NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = abstracts[\"final_frqwds_removed\"]\n",
    "\n",
    "clean_docs = []\n",
    "for doc in docs:\n",
    "    doc = ast.literal_eval(doc)\n",
    "    clean_docs.append(doc)\n",
    "    \n",
    "text = []\n",
    "for abstract in clean_docs:\n",
    "    text.append(\" \".join(abstract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['direct',\n",
       " 'identification',\n",
       " 'basic',\n",
       " 'apply',\n",
       " 'scientific',\n",
       " 'implementation',\n",
       " 'ensure',\n",
       " 'optimum',\n",
       " 'management',\n",
       " 'forest',\n",
       " 'administration',\n",
       " 'scientist',\n",
       " 'discipline']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'direct identification basic apply scientific implementation ensure optimum management forest administration scientist discipline'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=1.0, min_df=3)\n",
    "tf_idf = tfidf_vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7658, 10966)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure the number of terms (column) is less the 100,000\n",
    "#if greater than 100,000, use the number of terms as the keep_n parameter\n",
    "tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVars(docs):\n",
    "    # Create the variables needed for NMF from df[final_frqwds_removed]: dictionary (id2word), corpus\n",
    "    \n",
    "    # Create Dictionary\n",
    "    id2word = gensim.corpora.Dictionary(docs)\n",
    "    id2word.filter_extremes(no_below=3, no_above=1.0,  keep_n = 100000)\n",
    "    \n",
    "    # Create Corpus (Term Document Frequency)\n",
    "    #Creates a count for each unique word appearing in the document, where the word_id is substituted for the word\n",
    "    corpus = [id2word.doc2bow(doc) for doc in docs]\n",
    "\n",
    "    return id2word, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use keep_n = 100,000 defalt.\n"
     ]
    }
   ],
   "source": [
    "#TODO: run the following code to generate id2word and corpus\n",
    "id2word, corpus = createVars(clean_docs)\n",
    "#TODO: RENAME the file, run the code to save the output\n",
    "docs  = clean_docs\n",
    "#pickle.dump([corpus, id2word, docs], open('../../data/dspg21RnD/coherence_vars_bert2.sav','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Coherence file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Read in your coherence data (change the name of the file)\n",
    "f = open('../../data/dspg21RnD/coherence_vars_bert2.sav', 'rb')\n",
    "[corpus, id2word, docs] = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7658"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['direct',\n",
       " 'identification',\n",
       " 'basic',\n",
       " 'apply',\n",
       " 'scientific',\n",
       " 'implementation',\n",
       " 'ensure',\n",
       " 'optimum',\n",
       " 'management',\n",
       " 'forest',\n",
       " 'administration',\n",
       " 'scientist',\n",
       " 'discipline']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for doc in docs:\n",
    "    text.append(\" \".join(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'direct identification basic apply scientific implementation ensure optimum management forest administration scientist discipline'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function slightly modified from https://nlpforhackers.io/topic-modeling/\n",
    "\n",
    "def print_topics(model, vectorizer, top_n=10):\n",
    "    for idx, topic in enumerate(model.components_):  # loop through each row of H.  idx = row index.  topic = actual row\n",
    "        print(\"\\nTopic %d:\" % (idx))\n",
    "        #print([(vectorizer.get_feature_names()[i], topic[i])  # printing out words corresponding to indices found in next line\n",
    "                        #for i in topic.argsort()[:-top_n - 1:-1]])  # finding indices of top words in topic\n",
    "            \n",
    "        print_list = [(vectorizer.get_feature_names()[i], topic[i])  \n",
    "                        for i in topic.argsort()[:-top_n - 1:-1]]\n",
    "        for item in print_list:\n",
    "            print(item)\n",
    "            \n",
    "# Function to format topics as a \"list of list of strings\".\n",
    "# Needed for topic coherence function in Gensim\n",
    "\n",
    "# function modified from https://nlpforhackers.io/topic-modeling/\n",
    "\n",
    "def list_topics(model, vectorizer, top_n=10):\n",
    "\n",
    "    #input. top_n: how many words to list per topic.  If -1, then list all words.\n",
    "       \n",
    "    topic_words = []\n",
    "    \n",
    "    for idx, topic in enumerate(model.components_):  # loop through each row of H.  idx = row index.  topic = actual row\n",
    "            \n",
    "        if top_n == -1:   \n",
    "            topic_words.append([vectorizer.get_feature_names()[i] for i in topic.argsort()[::-1]])\n",
    "        else:\n",
    "            topic_words.append([vectorizer.get_feature_names()[i] for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "        \n",
    "    return topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create document-term matrix - TFIDF \n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=1.0, min_df=3)\n",
    "tf_idf = tfidf_vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function adapted from https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/\n",
    "\n",
    "def nmf_metrics(doc_term_matrix, n_topics, vectorizer, corpus, id2word, docs, rand_start):\n",
    "    \"\"\"\n",
    "    Compute c_v topic coherence for various number of topics\n",
    "    Parameters:\n",
    "    ----------\n",
    "    tf_idf\n",
    "    n_topics : list of number of topics\n",
    "    Returns:\n",
    "    -------\n",
    "    coherence_values : c_v topic coherence values corresponding to the NMF model with respective number of topics\n",
    "    \"\"\"\n",
    "    \n",
    "    coherence_values = []\n",
    "    \n",
    "    i = rand_start\n",
    "    for num_topics in n_topics:\n",
    "\n",
    "        # create model\n",
    "        t1 = time.time()\n",
    "        nmf_model = NMF(n_components=num_topics, random_state = i)\n",
    "        nmf_model.fit_transform(doc_term_matrix)\n",
    "        t2 = time.time()\n",
    "        print(f\"  Model time: {t2-t1}\")\n",
    "        \n",
    "        # create list of topics\n",
    "        topics = list_topics(nmf_model, vectorizer, top_n=10)\n",
    "        \n",
    "        # calculate coherence\n",
    "        t1 = time.time()\n",
    "        \n",
    "        #TODO:manually adjust number of processes\n",
    "        cm = CoherenceModel(topics=topics, corpus=corpus, dictionary=id2word, texts=docs, \n",
    "                            coherence='c_v', #model for calculating coherence score\n",
    "                            processes=10 #for smaller corpus, pronesses= number of cores - 5\n",
    "                           ) #window_size=500 ) \n",
    "        coherence_values.append(cm.get_coherence())\n",
    "        t2 = time.time()\n",
    "        print(f\"  Coherence time: {t2-t1}\")\n",
    "        \n",
    "        # output completion message\n",
    "        i = i+1\n",
    "        print('Number of topics =', num_topics, \"complete.\")\n",
    "\n",
    "    return coherence_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "  Model time: 1.1127963066101074\n",
      "  Coherence time: 0.6914005279541016\n",
      "Number of topics = 5 complete.\n",
      "  Model time: 1.2639811038970947\n",
      "  Coherence time: 0.9571599960327148\n",
      "Number of topics = 10 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz3hs/.conda/envs/crystal_bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model time: 3.973792791366577\n",
      "  Coherence time: 1.2598192691802979\n",
      "Number of topics = 15 complete.\n",
      "  Model time: 3.356252908706665\n",
      "  Coherence time: 1.4911510944366455\n",
      "Number of topics = 20 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz3hs/.conda/envs/crystal_bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model time: 6.984228134155273\n",
      "  Coherence time: 2.0317554473876953\n",
      "Number of topics = 25 complete.\n",
      "  Model time: 7.8718883991241455\n",
      "  Coherence time: 2.1873152256011963\n",
      "Number of topics = 30 complete.\n",
      "  Model time: 5.267805099487305\n",
      "  Coherence time: 2.533888816833496\n",
      "Number of topics = 35 complete.\n",
      "  Model time: 8.182427167892456\n",
      "  Coherence time: 2.9799013137817383\n",
      "Number of topics = 40 complete.\n",
      "  Model time: 6.447145938873291\n",
      "  Coherence time: 3.2120890617370605\n",
      "Number of topics = 45 complete.\n",
      "  Model time: 11.465293169021606\n",
      "  Coherence time: 3.6982080936431885\n",
      "Number of topics = 50 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz3hs/.conda/envs/crystal_bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model time: 35.27620244026184\n",
      "  Coherence time: 5.662353992462158\n",
      "Number of topics = 75 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz3hs/.conda/envs/crystal_bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model time: 57.33943772315979\n",
      "  Coherence time: 7.737243175506592\n",
      "Number of topics = 100 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz3hs/.conda/envs/crystal_bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model time: 86.63659596443176\n",
      "  Coherence time: 10.275823831558228\n",
      "Number of topics = 125 complete.\n",
      "Iteration 1\n",
      "  Model time: 0.7682812213897705\n",
      "  Coherence time: 0.6696715354919434\n",
      "Number of topics = 5 complete.\n",
      "  Model time: 1.2433891296386719\n",
      "  Coherence time: 0.9613661766052246\n",
      "Number of topics = 10 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz3hs/.conda/envs/crystal_bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model time: 3.8983399868011475\n",
      "  Coherence time: 1.5140788555145264\n",
      "Number of topics = 15 complete.\n",
      "  Model time: 3.7046308517456055\n",
      "  Coherence time: 1.5215208530426025\n",
      "Number of topics = 20 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz3hs/.conda/envs/crystal_bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model time: 6.963602066040039\n",
      "  Coherence time: 1.893995761871338\n",
      "Number of topics = 25 complete.\n",
      "  Model time: 5.861353397369385\n",
      "  Coherence time: 2.1568398475646973\n",
      "Number of topics = 30 complete.\n",
      "  Model time: 5.5713043212890625\n",
      "  Coherence time: 2.5858254432678223\n",
      "Number of topics = 35 complete.\n",
      "  Model time: 6.649319887161255\n",
      "  Coherence time: 2.8168413639068604\n",
      "Number of topics = 40 complete.\n",
      "  Model time: 15.217309713363647\n",
      "  Coherence time: 3.40199613571167\n",
      "Number of topics = 45 complete.\n",
      "  Model time: 6.563232660293579\n",
      "  Coherence time: 3.6983118057250977\n",
      "Number of topics = 50 complete.\n",
      "  Model time: 20.264283180236816\n",
      "  Coherence time: 5.827692985534668\n",
      "Number of topics = 75 complete.\n",
      "  Model time: 52.13991332054138\n",
      "  Coherence time: 7.773189067840576\n",
      "Number of topics = 100 complete.\n",
      "  Model time: 49.040477991104126\n",
      "  Coherence time: 10.339492797851562\n",
      "Number of topics = 125 complete.\n",
      "Iteration 2\n",
      "  Model time: 0.7754945755004883\n",
      "  Coherence time: 0.6737408638000488\n",
      "Number of topics = 5 complete.\n",
      "  Model time: 1.2854058742523193\n",
      "  Coherence time: 0.9598941802978516\n",
      "Number of topics = 10 complete.\n",
      "  Model time: 1.5530331134796143\n",
      "  Coherence time: 1.238851547241211\n",
      "Number of topics = 15 complete.\n",
      "  Model time: 3.1008903980255127\n",
      "  Coherence time: 1.4570508003234863\n",
      "Number of topics = 20 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz3hs/.conda/envs/crystal_bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model time: 6.902125120162964\n",
      "  Coherence time: 1.9639337062835693\n",
      "Number of topics = 25 complete.\n",
      "  Model time: 5.324630498886108\n",
      "  Coherence time: 2.211750030517578\n",
      "Number of topics = 30 complete.\n",
      "  Model time: 5.469724178314209\n",
      "  Coherence time: 2.4804341793060303\n",
      "Number of topics = 35 complete.\n",
      "  Model time: 5.08561635017395\n",
      "  Coherence time: 3.013681411743164\n",
      "Number of topics = 40 complete.\n",
      "  Model time: 13.394046068191528\n",
      "  Coherence time: 3.2874176502227783\n",
      "Number of topics = 45 complete.\n",
      "  Model time: 10.61403489112854\n",
      "  Coherence time: 3.728245496749878\n",
      "Number of topics = 50 complete.\n",
      "  Model time: 28.58300232887268\n",
      "  Coherence time: 5.921975135803223\n",
      "Number of topics = 75 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz3hs/.conda/envs/crystal_bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model time: 59.06266903877258\n",
      "  Coherence time: 7.814475059509277\n",
      "Number of topics = 100 complete.\n",
      "  Model time: 89.72351741790771\n",
      "  Coherence time: 10.67226266860962\n",
      "Number of topics = 125 complete.\n",
      "Iteration 3\n",
      "  Model time: 0.8050787448883057\n",
      "  Coherence time: 0.7002229690551758\n",
      "Number of topics = 5 complete.\n",
      "  Model time: 1.3288311958312988\n",
      "  Coherence time: 0.9806520938873291\n",
      "Number of topics = 10 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz3hs/.conda/envs/crystal_bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model time: 4.106259822845459\n",
      "  Coherence time: 1.566741704940796\n",
      "Number of topics = 15 complete.\n",
      "  Model time: 3.4705235958099365\n",
      "  Coherence time: 1.5153546333312988\n",
      "Number of topics = 20 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz3hs/.conda/envs/crystal_bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model time: 7.393334150314331\n",
      "  Coherence time: 1.8782958984375\n",
      "Number of topics = 25 complete.\n",
      "  Model time: 5.1716392040252686\n",
      "  Coherence time: 2.200763463973999\n",
      "Number of topics = 30 complete.\n",
      "  Model time: 5.840053081512451\n",
      "  Coherence time: 2.644679307937622\n",
      "Number of topics = 35 complete.\n",
      "  Model time: 7.761369466781616\n",
      "  Coherence time: 2.8709285259246826\n",
      "Number of topics = 40 complete.\n",
      "  Model time: 6.288424968719482\n",
      "  Coherence time: 3.27854323387146\n",
      "Number of topics = 45 complete.\n",
      "  Model time: 11.450202703475952\n",
      "  Coherence time: 3.665147304534912\n",
      "Number of topics = 50 complete.\n",
      "  Model time: 30.55134081840515\n",
      "  Coherence time: 6.046535968780518\n",
      "Number of topics = 75 complete.\n",
      "  Model time: 56.54573917388916\n",
      "  Coherence time: 7.826183557510376\n",
      "Number of topics = 100 complete.\n",
      "  Model time: 85.68906307220459\n",
      "  Coherence time: 10.575822114944458\n",
      "Number of topics = 125 complete.\n",
      "Iteration 4\n",
      "  Model time: 0.7933602333068848\n",
      "  Coherence time: 0.6780376434326172\n",
      "Number of topics = 5 complete.\n",
      "  Model time: 1.3016836643218994\n",
      "  Coherence time: 0.9667575359344482\n",
      "Number of topics = 10 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz3hs/.conda/envs/crystal_bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model time: 4.084392547607422\n",
      "  Coherence time: 1.2412874698638916\n",
      "Number of topics = 15 complete.\n",
      "  Model time: 3.91092848777771\n",
      "  Coherence time: 1.515458583831787\n",
      "Number of topics = 20 complete.\n",
      "  Model time: 5.591097354888916\n",
      "  Coherence time: 1.831383466720581\n",
      "Number of topics = 25 complete.\n",
      "  Model time: 5.612567663192749\n",
      "  Coherence time: 2.3275649547576904\n",
      "Number of topics = 30 complete.\n",
      "  Model time: 8.965773582458496\n",
      "  Coherence time: 2.5669238567352295\n",
      "Number of topics = 35 complete.\n",
      "  Model time: 6.586566686630249\n",
      "  Coherence time: 2.848316192626953\n",
      "Number of topics = 40 complete.\n",
      "  Model time: 12.149762392044067\n",
      "  Coherence time: 3.610668420791626\n",
      "Number of topics = 45 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz3hs/.conda/envs/crystal_bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model time: 17.96056032180786\n",
      "  Coherence time: 3.768014907836914\n",
      "Number of topics = 50 complete.\n",
      "  Model time: 33.52816104888916\n",
      "  Coherence time: 6.0313026905059814\n",
      "Number of topics = 75 complete.\n",
      "  Model time: 48.196704149246216\n",
      "  Coherence time: 7.966750621795654\n",
      "Number of topics = 100 complete.\n",
      "  Model time: 68.61280179023743\n",
      "  Coherence time: 10.46601676940918\n",
      "Number of topics = 125 complete.\n",
      "Iteration 5\n",
      "  Model time: 0.795116662979126\n",
      "  Coherence time: 0.6755280494689941\n",
      "Number of topics = 5 complete.\n",
      "  Model time: 1.3044605255126953\n",
      "  Coherence time: 0.9600212574005127\n",
      "Number of topics = 10 complete.\n",
      "  Model time: 1.112351655960083\n",
      "  Coherence time: 1.291261911392212\n",
      "Number of topics = 15 complete.\n",
      "  Model time: 4.857828617095947\n",
      "  Coherence time: 1.7780160903930664\n",
      "Number of topics = 20 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zz3hs/.conda/envs/crystal_bert/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model time: 7.3296802043914795\n",
      "  Coherence time: 1.9288251399993896\n",
      "Number of topics = 25 complete.\n",
      "  Model time: 6.608461380004883\n",
      "  Coherence time: 2.131995677947998\n",
      "Number of topics = 30 complete.\n",
      "  Model time: 4.594269037246704\n",
      "  Coherence time: 2.510430097579956\n",
      "Number of topics = 35 complete.\n",
      "  Model time: 7.561211109161377\n",
      "  Coherence time: 3.061439275741577\n",
      "Number of topics = 40 complete.\n",
      "  Model time: 10.162342548370361\n",
      "  Coherence time: 3.208566427230835\n",
      "Number of topics = 45 complete.\n",
      "  Model time: 10.863919973373413\n",
      "  Coherence time: 3.844336986541748\n",
      "Number of topics = 50 complete.\n"
     ]
    }
   ],
   "source": [
    "# code copied from https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/\n",
    "# minor alterations made\n",
    "n_topics = list(range(5,51,5)) + [75,100,125] #takes about 4-5 hrs to run\n",
    "\n",
    "num_runs = 10\n",
    "\n",
    "col_names = [f\"iteration {i}\" for i in range(num_runs)]\n",
    "nmf_c = pd.DataFrame(index = n_topics, columns = col_names)\n",
    "\n",
    "for i in range(num_runs):\n",
    "    print(f\"Iteration {i}\")\n",
    "    \n",
    "    # run models\n",
    "    c = nmf_metrics(doc_term_matrix=tf_idf, n_topics=n_topics, vectorizer=tfidf_vectorizer, \n",
    "                         corpus=corpus, id2word=id2word, docs=docs, rand_start = (i)*len(n_topics))\n",
    "    \n",
    "    # save results\n",
    "    nmf_c[f\"iteration {i}\"] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: save results as csv, no need to save as pickle file anymore, change file name\n",
    "nmf_c['n_topics'] = nmf_c.index\n",
    "#nmf_c.to_pickle(\"/home/zz3hs/git/dspg21RnD/data/dspg21RnD/nmf_coherence_XXX.pkl\")\n",
    "nmf_c.to_csv(\"/home/zz3hs/git/dspg21RnD/data/dspg21RnD/nmf_coherence_xxx.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-crystal_bert]",
   "language": "python",
   "name": "conda-env-.conda-crystal_bert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
