{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling DNA Data Report \n",
    "\n",
    "This Jupyter Notebook contains the code for all of the profiling done on the DNA dataset. \n",
    "## Outline\n",
    "* Inventory of Dataset \n",
    "    * Validity Check of the following variables:\n",
    "         * Company-Related Columns: company codes...occur,about,lineage,association,relevance\n",
    "         * Body (word count) \n",
    "         * Publication DateTime (Year) \n",
    "    * Table for Completeness, Uniqueness and Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #why is this used\n",
    "import pandas as pd #why is the used\n",
    "import json #the json package is loaded in order to read in the data set \n",
    "import gzip #the gzip package is loaded in order to read in the data set\n",
    "from collections import Counter #the counter is imported to count frequency\n",
    "from datetime import datetime as dt #this package is imported to convert datetime structure to year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f5d3c1cc2461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/original/DNA_DATA_FULL.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m     )\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data_from_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \"\"\"\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/software/standard/compiler/gcc/7.1.0/jupyter_conda/2019.10-py3.7/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dna_df = pd.read_json('../data/original/DNA_DATA_FULL.gz', compression='gzip') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Validity Check for Company-Related Columns</b></h1>\n",
    "<h4>Validity for company-related columns was defined as having a company in the DNA column of interest that existed in the company codes dictionary provided by Dow Jones DNA. This validity check ensured that all the valid companies codes were associated with the full company name. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Getting only the columns that deal with the company codes</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking only at the company columns\n",
    "#companies = df[['company_codes', 'company_codes_occur', 'company_codes_about', 'company_codes_lineage', 'company_codes_association', 'company_codes_relevance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are no values in this column so it will not be part of the validating process\n",
    "#print(companies['company_codes_association'].value_counts())\n",
    "companies = dna_df[['company_codes', 'company_codes_occur', 'company_codes_about', 'company_codes_lineage', 'company_codes_relevance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Loading in company code dictionary</b></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading the data dictionary into a dataframe\n",
    "code_dict = pd.read_csv(\"../data/original/companies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Creating a profile table for validity</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For validating, I will be taking each unique company code in all of the columns and checking to see if each one is in the company codes dictionary\n",
    "#The dataframe below will keep track of the % of valid company codes\n",
    "#profile = pd.DataFrame({\"Validity\": np.zeros(len(companies.columns))}).set_index(companies.columns)\n",
    "validity_col = df[['company_codes', 'company_codes_occur', 'company_codes_about', 'company_codes_lineage', 'company_codes_relevance', 'body', 'publication_datetime']]\n",
    "profile = pd.DataFrame({\"Validity\": np.zeros(7)}).set_index(validity_col.columns)\n",
    "\n",
    "#profile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Creating validity function</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the validity function I will be using\n",
    "#returns the sum of True and divides by the length of the unique list\n",
    "def checkValidity(ls, col = code_dict.code.tolist()):\n",
    "    return sum([code in col for code in ls]) / len(ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Getting unique codes for each column</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TPMJTY', 'ITLCOR', 'NYRKMD', 'FRJNS', 'CLYCAP', 'GROUP', 'IPLNN', 'SMLBSL', 'PKDEAG', 'HFNTIR']\n",
      "There are 73688 unique company codes\n"
     ]
    }
   ],
   "source": [
    "#Getting the unique company codes\n",
    "unique_company_codes = set() #defining an empty set, a set only allows unique value \n",
    "for value in companies['company_codes']: #for each input in the column company_codes\n",
    "    unique_company_codes.update(value.split(\",\")) #add the company code input to the empty set, seperate each value with a comma\n",
    "\n",
    "#Convert set back to list\n",
    "unique_company_codes = list(unique_company_codes)\n",
    "unique_company_codes = unique_company_codes[1:] #The first element was '', so I didn't include it in the final list\n",
    "unique_company_codes = [word.upper() for word in unique_company_codes] #convert all the characters into upper case to match case of dictionar\n",
    "print(unique_company_codes[0:10]) #print the first 10 unique companies\n",
    "print(\"There are {} unique company codes\".format(len(unique_company_codes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TPMJTY', 'ITLCOR', 'NYRKMD', 'FRJNS', 'CLYCAP', 'GROUP', 'IPLNN', 'SMLBSL', 'PKDEAG', 'HFNTIR']\n",
      "There are 62381 unique companies in unique_companies_occur\n"
     ]
    }
   ],
   "source": [
    "#Unique companies from company_codes_occur\n",
    "unique_companies_occur = set()  #defining an empty set, a set only allows unique value \n",
    "\n",
    "for value in dna_df['company_codes_occur']: #for each input in the column company_codes_occur \n",
    "    unique_companies_occur.update(value.split(\",\")) #add the company code input to the empty set, seperate each value with a comma\n",
    "\n",
    "unique_companies_occur = list(unique_companies_occur)\n",
    "unique_companies_occur = unique_companies_occur[1:] #The first element was '', so I didn't include it in the final list\n",
    "unique_companies_occur = [word.upper() for word in unique_companies_occur]  #convert all the characters into upper case to match case of dictionar\n",
    "print(unique_companies_occur[0:10]) #print the first 10 unique companies\n",
    "print(\"There are {} unique companies in unique_companies_occur\".format(len(unique_companies_occur))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TPMJTY', 'ITLCOR', 'NYRKMD', 'FRJNS', 'CLYCAP', 'GROUP', 'PKDEAG', 'HUNA', 'KPMG', 'VMNTVE']\n",
      "There are 30780 unique companies in unique_companies_about\n"
     ]
    }
   ],
   "source": [
    "#unique companies from company_codes_about\n",
    "unique_companies_about = set() #defining an empty set, a set only allows unique value \n",
    "\n",
    "for value in dna_df['company_codes_about']: #for each input in the column company_codes_about \n",
    "    unique_companies_about.update(value.split(\",\"))\n",
    "\n",
    "unique_companies_about = list(unique_companies_about) \n",
    "unique_companies_about = unique_companies_about[1:] #The first element was '', so I didn't include it in the final list\n",
    "unique_companies_about = [word.upper() for word in unique_companies_about] #convert all the characters into upper case to match case of dictionary\n",
    "print(unique_companies_about[0:10]) #print the first 10 unique companies \n",
    "print(\"There are {} unique companies in unique_companies_about\".format(len(unique_companies_about)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TPMJTY', 'ITLCOR', 'NYRKMD', 'FRJNS', 'CLYCAP', 'GROUP', 'IPLNN', 'SMLBSL', 'HFNTIR', 'PKDEAG']\n",
      "There are 66451 unique companies in unique_companies_relevance\n"
     ]
    }
   ],
   "source": [
    "#unique companies from company_codes_relevance\n",
    "unique_companies_relevance = set()\n",
    "\n",
    "for value in dna_df['company_codes_relevance']:\n",
    "    unique_companies_relevance.update(value.split(\",\"))\n",
    "\n",
    "unique_companies_relevance = list(unique_companies_relevance)\n",
    "unique_companies_relevance = unique_companies_relevance[1:] #The first element was '', so I didn't include it in the final list\n",
    "unique_companies_relevance = [word.upper() for word in unique_companies_relevance]  #convert all the characters into upper case to match case of dictionar\n",
    "print(unique_companies_relevance[0:10]) #print the first 10 unique companies\n",
    "print(\"There are {} unique companies in unique_companies_relevance\".format(len(unique_companies_relevance)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZYMEHA', 'CEVEGL', 'BORNGI', 'CMAJLI', 'PKDEAG', 'TIGEN', 'WALJ', 'LUGQKV', 'CELGEN', 'PEPRT']\n",
      "There are 3467 unique companies in unique_companies_lineage\n"
     ]
    }
   ],
   "source": [
    "#unique companies from company_codes_lineage\n",
    "unique_companies_lineage = set()\n",
    "\n",
    "for value in dna_df['company_codes_lineage']:\n",
    "    unique_companies_lineage.update(value.split(\",\"))\n",
    "\n",
    "unique_companies_lineage = list(unique_companies_lineage)\n",
    "unique_companies_lineage = unique_companies_lineage[1:] #The first element was '', so I didn't include it in the final list\n",
    "\n",
    "#Convert to uppercase bc data dictionary has all codes in upper case\n",
    "unique_companies_lineage = [word.upper() for word in unique_companies_lineage]  #convert all the characters into upper case to match case of dictionar\n",
    "print(unique_companies_lineage[0:10]) #print the first 10 unique companies\n",
    "print(\"There are {} unique companies in unique_companies_lineage\".format(len(unique_companies_lineage)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Creating validity function</b></h3>\n",
    "<h4> This function checks to see if each of the company codes in the column of interest exist in the company codes dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'code_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-96fb7a7d5f9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#returns the sum of True and divides by the length of the unique list aka the ratio of valid companies from 0-1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#true is defined as having the company codes exist in the company codes dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcheckValidity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#ls is the list of the column of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#this checks that each company code in the company dictionary is found in the column of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'code_dict' is not defined"
     ]
    }
   ],
   "source": [
    "#Here is the validity function I will be using\n",
    "#returns the sum of True and divides by the length of the unique list aka the ratio of valid companies from 0-1\n",
    "#true is defined as having the company codes exist in the company codes dictionary\n",
    "def checkValidity(ls, col = code_dict.code.tolist()): #ls is the list of the column of interest\n",
    "    return sum([code in col for code in ls]) / len(ls) #this checks that each company code in the company dictionary is found in the column of interest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Checking validity for each column and applying the result to the profile table</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.iloc[0] = 86.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.iloc[1] = checkValidity(unique_companies_occur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.iloc[2] = checkValidity(unique_companies_about)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(checkValidity(unique_companies_lineage))\n",
    "profile.iloc[3] = checkValidity(unique_companies_lineage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.iloc[4] = checkValidity(unique_companies_relevance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Company Code Validity Results</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>company_codes</th>\n",
       "      <td>86.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_occur</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_about</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_lineage</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_relevance</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_datetime</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Validity\n",
       "company_codes                86.9\n",
       "company_codes_occur           0.0\n",
       "company_codes_about           0.0\n",
       "company_codes_lineage         0.0\n",
       "company_codes_relevance       0.0\n",
       "body                          0.0\n",
       "publication_datetime          0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Getting the invalid company codes</b></h3>\n",
    "<h4> We are interested in obtaining the invalid company codes to understand the gap between the company codes dictionary and the companies mentioned in articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all the invalid company codes\n",
    "invalid_company_codes = np.array([]) #defining an empty array to input all invalid company codes\n",
    "for co in unique_company_codes: #for company in unique company codes, we are interested in unique company codes because \n",
    "    if co not in code_dict.code.tolist(): #if the company code is not found in the company codes dictionary\n",
    "        invalid_company_codes = np.append(invalid_company_codes, co)   #then add the company codes to the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9683 invalid companies\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} invalid companies\".format(len(invalid_company_codes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Added a csv to the working folder that has all the invalid company codes from the company codes column</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the codes that are in the dataset but not in the data dictionary\n",
    "invalid_df = pd.DataFrame()\n",
    "invalid_df['code'] = invalid_company_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_df.to_csv(\"../data/working/invalidcompanycodes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Double checking to make sure that no codes in the invalid_company_codes list are valid (Should get 0% valid)</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(checkValidity(invalid_company_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Listing some of the invalid codes (aka codes in the dataset but not in the dictionary)</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['KUKXBV', 'AMSFFRA', 'LUNFCI', 'GANCMM', 'INSTLC', 'BZHTAKX',\n",
       "       'BFLMII', 'LVDTIN', 'DALNGEZ', 'CUCMAL', 'CRPZJHJ', 'AHMUCPH',\n",
       "       'CADRHL', 'RHALUM', 'AWTRA', 'AKVYHCU', 'ORTHVT', 'KLINGC',\n",
       "       'KLICO', 'REESSQ', 'WELHGL', 'MOCENU', 'APPUDYG', 'COJZCJA',\n",
       "       'CSUFFR', 'OCOUHD', 'GNTXUI', 'NOVPLL', 'NIKOUI', 'PITTOI'],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_company_codes[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7e3cfc602257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Row'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "dna_df['Row'] = np.arange(0, len(df)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Filtering through the dataset and keeping track of rows with at least one invalid company in them</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_row = [] #setting an empty list\n",
    "for row in dna_df.itertuples(): #for row in dna company columns\n",
    "    for code in row.company_codes.split(\",\"): #for company code in company_codes column\n",
    "        if code.upper() in invalid_company_codes: #if the company code in upper case is in invalid company company code\n",
    "            invalid_row.append(row.Row) #add the row number with the invalid company to the invalid row list \n",
    "\n",
    "invalid_row = set(invalid_row) #only the unique rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_row = list(invalid_row) #return the set back to a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_row.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 161321 rows with at least one invalid company code in the company_codes column, which is about 8.303295922752856% of the entire dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} rows with at least one invalid company code in the company_codes column, which is about {}% of the entire dataset\".format(len(invalid_row),  len(invalid_row) / len(df) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 19, 35, 38, 59, 67, 68, 70, 72, 94, 108, 121, 134, 139, 146, 159, 161, 164, 184, 201, 203, 211, 251, 255, 263, 277, 283, 316, 322, 331, 341, 347, 379, 390, 412, 428, 434, 439, 458, 460, 462, 464, 509, 519, 532, 538, 547, 560, 577, 612, 613, 629, 639, 645, 653, 677, 695, 703, 714, 735, 746, 761, 770, 780, 831, 832, 872, 878, 884, 890, 906, 921, 923, 939, 945, 951, 954, 956, 964, 993, 1015, 1046, 1052, 1056, 1062, 1067, 1071, 1072, 1075, 1077, 1078, 1082, 1087, 1129, 1158, 1159, 1163, 1172, 1188, 1212]\n"
     ]
    }
   ],
   "source": [
    "#First 100 invalid rows\n",
    "print(invalid_row[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Validity check for Body** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in ensuring the data set only includes written articles and excludes quick news on a given company. Furthermore, given the capacity of the machine learning algorithms we inted to use on this text, we have decide to limit the amount of words in the article to 10,000. This sets the criteria for a valid entry of body to be more than 100 words, but less than 10,000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping all the columns except for body\n",
    "text = dna_df['body'].fillna(\"Nothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathering the word count for each row\n",
    "word_count_all = []\n",
    "\n",
    "for words in text:\n",
    "   word_count_all.append(int(len(words.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "validity_body_all = []\n",
    "\n",
    "#creates a loop where any text with less than 100 words or more than 10,000 words is considered an invalid \n",
    "#data point. The reason for these numbers are that anything less than 100 words does not fit our definition of\n",
    "#an article and anything longer than 10,000 words is too long for us to check?\n",
    "for number in word_count_all:\n",
    "    if number < 100:\n",
    "        validity_body_all.append(0)\n",
    "        \n",
    "    elif number > 10000:\n",
    "        validity_body_all.append(0)\n",
    "        \n",
    "    else:\n",
    "        validity_body_all.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78%, or 1520983 of the data in body are valid\n"
     ]
    }
   ],
   "source": [
    "#Validity percentage\n",
    "all_total_valid = sum(validity_body_all)\n",
    "\n",
    "print('{}%, or'.format(round(all_total_valid/len(validity_body_all)*100)), all_total_valid, 'of the data in body are valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a data frame with all the valid body points along with the body info\n",
    "valid_df = pd.DataFrame()\n",
    "valid_df['body'] = df['body']\n",
    "valid_df['word_count'] = word_count_all\n",
    "valid_df['validity'] = validity_body_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421872, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check which of these rows specifically are invalid \n",
    "invalid_body = valid_df['validity'] == 0\n",
    "invalid_body_text = valid_df[invalid_body]\n",
    "invalid_body_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Validity check for Publication Date**\n",
    "\n",
    "#### We are interested in obtaining articles that were **published** from 2010 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = dna_df['publication_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms the date from timestamp to a string \n",
    "dates_all_iso = [] #empty list to keep track of years \n",
    "\n",
    "for date in dates: #for datetime date in the column publication_datetime\n",
    "     dates_all_iso.append(dt.fromtimestamp(date/1000.0).strftime('%Y')) #convert the datetime structure to a year we understand and add to the list, must divide date by 10000 as the datetime is kept in miliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_date_all_df = pd.DataFrame() #creates an empty dataframe to keep track of valid dates\n",
    "valid_date_all_df['Date'] = dates_all_iso #add column that contains the dates \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#years should be 2010 and onwards. We realllly expect to see 2013-2018 though\n",
    "validity_date_all = list((valid_date_all_df['Date'] > '2009'))\n",
    "\n",
    "valid_date_all_df['Validity'] = validity_date_all #add column that has True or False if column date is has input on or after 2009 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%, or 1942855 of the data in modification datetime are valid\n"
     ]
    }
   ],
   "source": [
    "print('{}%, or'.format(round(sum(valid_date_all_df['Validity'] == True) / len(valid_date_all_df['Validity']) * 100)), '{} of the data in modification datetime are valid'.format(sum(valid_date_all_df['Validity'] == True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar plot of the number of articles in DNA per year\n",
    "#Trying to answer the question: does it meet our expecation?: We realllly expect to see 2013-2018 though\n",
    "#count each occurence of year value in df and plot\n",
    "valid_date_all_df['Date'].value_counts().sort_index().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv subsets for 2013-2018 year\n",
    "#df2013 = df[df['Year'] == '2013']\n",
    "\n",
    "#for i in range(2013, 2019):\n",
    " #   df_year = df[df['Year'] == str(i)]\n",
    "  #  df_year.to_csv(\"../data/working/DNA_\" + str(i) + \".csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding publication date and body to validity table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>company_codes</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_occur</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_about</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_lineage</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_relevance</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_datetime</th>\n",
       "      <td>0.78286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Validity\n",
       "company_codes             0.00000\n",
       "company_codes_occur       0.00000\n",
       "company_codes_about       0.00000\n",
       "company_codes_lineage     0.00000\n",
       "company_codes_relevance   0.00000\n",
       "body                      1.00000\n",
       "publication_datetime      0.78286"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#publication is actually 100% valid, and body is .78286% valid\n",
    "profile.iloc[5] = sum(valid_date_all_df['Validity'] == True) / len(valid_date_all_df['Validity']) #proportion of entries that pass date validity  check\n",
    "profile.iloc[6] = all_total_valid/len(validity_body_all) #proportion of entries in body that pass validity check \n",
    "\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Completeness, Uniqueness, and Duplicates</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create profiling dataframe\n",
    "prof = pd.DataFrame({\"Completeness\": np.zeros(len(df.columns)).astype(int), \"Uniqueness\": np.zeros(len(df.columns)).astype(int),\"Duplicates\": np.zeros(len(df.columns)).astype(int)}).set_index(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Functions for Completeness, Uniqueness, and Duplicates</b><h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCompleteness(col): \n",
    "    return sum(~col.isnull()) / len(col) #return the proportion of entries in the dataframe that are empty to entire dataframe\n",
    "\n",
    "#NaN not counted as unique\n",
    "def isUnique(col):\n",
    "    return (len(col.unique()) - sum(col.isnull().unique())) / (len(col) - sum(col.isnull())) #return the fraction/proportion of unique values excluding NaN values \n",
    "\n",
    "def checkDuplicates(col):\n",
    "    return sum(col.duplicated()) / len(col) #return the proportion of duplicates in the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Applying each function</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying completeness to a df\n",
    "prof['Completeness'] = dna_df.apply(findCompleteness)\n",
    "\n",
    "#Applying the unique function\n",
    "prof['Uniqueness'] = dna_df.apply(isUnique)\n",
    "\n",
    "#Applying the duplicate function\n",
    "prof['Duplicates'] = dna_df.apply(checkDuplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Profile</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Uniqueness</th>\n",
       "      <th>Duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>copyright</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.014934e-03</td>\n",
       "      <td>0.992985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.732466e-01</td>\n",
       "      <td>0.826753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.040685e-02</td>\n",
       "      <td>0.989593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modification_datetime</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.468182e-01</td>\n",
       "      <td>0.353182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <td>0.975772</td>\n",
       "      <td>8.207384e-01</td>\n",
       "      <td>0.199146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_occur</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.813707e-01</td>\n",
       "      <td>0.818629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_about</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.813290e-02</td>\n",
       "      <td>0.901867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_lineage</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.418755e-03</td>\n",
       "      <td>0.995581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snippet</th>\n",
       "      <td>0.988084</td>\n",
       "      <td>9.037721e-01</td>\n",
       "      <td>0.106997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_date</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.116277e-01</td>\n",
       "      <td>0.788372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_index_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.304125e-03</td>\n",
       "      <td>0.993696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.578687e-04</td>\n",
       "      <td>0.999042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.358825e-04</td>\n",
       "      <td>0.999864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_of_origin</th>\n",
       "      <td>0.999788</td>\n",
       "      <td>1.029631e-04</td>\n",
       "      <td>0.999897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ingestion_datetime</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.295663e-01</td>\n",
       "      <td>0.370434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modification_date</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.869020e-01</td>\n",
       "      <td>0.113098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_name</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.196767e-03</td>\n",
       "      <td>0.997803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language_code</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.147065e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.923275e-02</td>\n",
       "      <td>0.970767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_association</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.147065e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.579899e-02</td>\n",
       "      <td>0.914201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>byline</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.056430e-02</td>\n",
       "      <td>0.969436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes_relevance</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.585252e-01</td>\n",
       "      <td>0.741475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_code</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.105149e-03</td>\n",
       "      <td>0.997895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.242949e-03</td>\n",
       "      <td>0.992757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.621789e-01</td>\n",
       "      <td>0.637821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry_codes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.867213e-02</td>\n",
       "      <td>0.931328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.835670e-01</td>\n",
       "      <td>0.216433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_datetime</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.116277e-01</td>\n",
       "      <td>0.788372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publisher_name</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.339714e-04</td>\n",
       "      <td>0.999266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.029413e-06</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_type</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.147065e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section</th>\n",
       "      <td>0.448260</td>\n",
       "      <td>6.175186e-03</td>\n",
       "      <td>0.997231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dateline</th>\n",
       "      <td>0.013851</td>\n",
       "      <td>1.921519e-01</td>\n",
       "      <td>0.997338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Completeness    Uniqueness  Duplicates\n",
       "copyright                      1.000000  7.014934e-03    0.992985\n",
       "subject_codes                  1.000000  1.732466e-01    0.826753\n",
       "art                            1.000000  1.040685e-02    0.989593\n",
       "modification_datetime          1.000000  6.468182e-01    0.353182\n",
       "body                           0.975772  8.207384e-01    0.199146\n",
       "company_codes_occur            1.000000  1.813707e-01    0.818629\n",
       "company_codes_about            1.000000  9.813290e-02    0.901867\n",
       "company_codes_lineage          1.000000  4.418755e-03    0.995581\n",
       "snippet                        0.988084  9.037721e-01    0.106997\n",
       "publication_date               1.000000  2.116277e-01    0.788372\n",
       "market_index_codes             1.000000  6.304125e-03    0.993696\n",
       "credit                         1.000000  9.578687e-04    0.999042\n",
       "currency_codes                 1.000000  1.358825e-04    0.999864\n",
       "region_of_origin               0.999788  1.029631e-04    0.999897\n",
       "ingestion_datetime             1.000000  6.295663e-01    0.370434\n",
       "modification_date              1.000000  8.869020e-01    0.113098\n",
       "source_name                    1.000000  2.196767e-03    0.997803\n",
       "language_code                  1.000000  5.147065e-07    0.999999\n",
       "region_codes                   1.000000  2.923275e-02    0.970767\n",
       "company_codes_association      1.000000  5.147065e-07    0.999999\n",
       "person_codes                   1.000000  8.579899e-02    0.914201\n",
       "byline                         1.000000  3.056430e-02    0.969436\n",
       "company_codes_relevance        1.000000  2.585252e-01    0.741475\n",
       "source_code                    1.000000  2.105149e-03    0.997895\n",
       "an                             1.000000  1.000000e+00    0.000000\n",
       "word_count                     1.000000  7.242949e-03    0.992757\n",
       "company_codes                  1.000000  3.621789e-01    0.637821\n",
       "industry_codes                 1.000000  6.867213e-02    0.931328\n",
       "title                          1.000000  7.835670e-01    0.216433\n",
       "publication_datetime           1.000000  2.116277e-01    0.788372\n",
       "publisher_name                 1.000000  7.339714e-04    0.999266\n",
       "action                         1.000000  1.029413e-06    0.999999\n",
       "document_type                  1.000000  5.147065e-07    0.999999\n",
       "section                        0.448260  6.175186e-03    0.997231\n",
       "dateline                       0.013851  1.921519e-01    0.997338"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof.drop('Row', inplace = True)\n",
    "prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Put all the invalid company codes into a dataframe</b><h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_df = pd.read_csv(\"../data/working/invalidcompanycodes.csv\", index_col = [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Creating a valid company code dictionary</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_company_codes = invalid_df.code.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dict.rename(columns = {' description': 'description'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_companies = pd.DataFrame()\n",
    "valid_codes = np.array([])\n",
    "valid_desc = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in code_dict.itertuples():\n",
    "    if row.code in unique_company_codes:\n",
    "        valid_codes = np.append(valid_codes, row.code)\n",
    "        valid_desc = np.append(valid_desc, row.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_companies['Code'] = valid_codes\n",
    "valid_companies['Description'] = valid_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_companies.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_companies.to_csv(\"../data/working/validcompaniesdictionary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_valid_df = pd.read_csv(\"../data/working/validcompaniesdictionary.csv\", index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>AA PLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAADJ</td>\n",
       "      <td>Emperial Americas, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAAIY</td>\n",
       "      <td>American Academy of Allergy, Asthma and Immuno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAABBB</td>\n",
       "      <td>Bird Studies Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAACK</td>\n",
       "      <td>Aesculap AG &amp; Co. KG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Code                                        Description\n",
       "0      AA                                             AA PLC\n",
       "2  AAAADJ                            Emperial Americas, Inc.\n",
       "3  AAAAIY  American Academy of Allergy, Asthma and Immuno...\n",
       "5  AAABBB                                Bird Studies Canada\n",
       "6   AAACK                               Aesculap AG & Co. KG"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_valid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Conclusions</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Completeness, Uniqueness, and Duplicates</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Non-duplicates'] = [set(code) for code in df['company_codes'].str.split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Non-duplicates'] = [list(code) for code in df['Non-duplicates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Non-duplicates'] = [','.join(code) for code in df['Non-duplicates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Non-duplicates'] = df['Non-duplicates'].str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_codes</th>\n",
       "      <th>Non-duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,toamsi,toamsi,tosmsc,tosmsc,tshba,tshba,tshba,</td>\n",
       "      <td>tshba,toamsi,tosmsc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,irevs,irevs,irevs,</td>\n",
       "      <td>irevs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,euruno,</td>\n",
       "      <td>euruno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,retrac,nyse,nyse,retrac,retrac,seexc,</td>\n",
       "      <td>nyse,retrac,seexc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,brstmy,brstmy,brstmy,</td>\n",
       "      <td>brstmy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942850</th>\n",
       "      <td>,egalcu,egalcu,egalcu,seexc,</td>\n",
       "      <td>seexc,egalcu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942851</th>\n",
       "      <td>,endoph,schplo,endoph,endoph,jnsspi,jnsspi,jon...</td>\n",
       "      <td>schplo,endoph,jnsspi,seexc,jonjon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942852</th>\n",
       "      <td>,amchso,</td>\n",
       "      <td>amchso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942853</th>\n",
       "      <td>,grnlft,kalamc,stry,stry,stry,</td>\n",
       "      <td>grnlft,stry,kalamc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942854</th>\n",
       "      <td>,zogeni,ardgm,cowhrp,zogeni,zogeni,endoph,</td>\n",
       "      <td>zogeni,endoph,cowhrp,ardgm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1942855 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             company_codes  \\\n",
       "0          ,toamsi,toamsi,tosmsc,tosmsc,tshba,tshba,tshba,   \n",
       "1                                      ,irevs,irevs,irevs,   \n",
       "2                                                 ,euruno,   \n",
       "3                   ,retrac,nyse,nyse,retrac,retrac,seexc,   \n",
       "4                                   ,brstmy,brstmy,brstmy,   \n",
       "...                                                    ...   \n",
       "1942850                       ,egalcu,egalcu,egalcu,seexc,   \n",
       "1942851  ,endoph,schplo,endoph,endoph,jnsspi,jnsspi,jon...   \n",
       "1942852                                           ,amchso,   \n",
       "1942853                     ,grnlft,kalamc,stry,stry,stry,   \n",
       "1942854         ,zogeni,ardgm,cowhrp,zogeni,zogeni,endoph,   \n",
       "\n",
       "                            Non-duplicates  \n",
       "0                      tshba,toamsi,tosmsc  \n",
       "1                                    irevs  \n",
       "2                                   euruno  \n",
       "3                        nyse,retrac,seexc  \n",
       "4                                   brstmy  \n",
       "...                                    ...  \n",
       "1942850                       seexc,egalcu  \n",
       "1942851  schplo,endoph,jnsspi,seexc,jonjon  \n",
       "1942852                             amchso  \n",
       "1942853                 grnlft,stry,kalamc  \n",
       "1942854         zogeni,endoph,cowhrp,ardgm  \n",
       "\n",
       "[1942855 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['company_codes', 'Non-duplicates']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Validity: Defined here as codes that are not in the data dictionary</h4>\n",
    "<p>Looking at the validity of the company columns</p>\n",
    "<ol>\n",
    "    <li>Company_codes had just under 87% valid codes in its column. That means that of all the unique codes in this\n",
    "        column, 13% or so were not in the data dictionary</li>\n",
    "    <li>Company_codes_occur was 89% valid for all unique codes in its column</li>\n",
    "    <li>Both company_codes_about and company_codes_lineage were 99% valid</li>\n",
    "    <li>Company_codes_relevance was 86% valid</li>\n",
    "</ol>\n",
    "\n",
    "<p>There were 73,688 unique company codes in this dataset. Of those 73,688, 9683 were considered invalid since they did not appear in the data dictionary. This left 64,005 valid companies. Each company's code and name are provided in the validcompaniesdictionary.csv. A list of the invalid company codes are also available in the invalidcompanycodes.csv</p>\n",
    "\n",
    "<p>There were 161,321 rows in the DNA dataset that had at least one invalid company code in its company_codes column</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, we found that the DNA data set includes 35 different variables with 1942855 entries. 4.5% of those entries were missing an actual value. Additionally, we tested seven variables for validity. The validation criteria depended uniquely on the variable. Overall, we found 78.3 % of the entire data set passed all of the validity checks. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
