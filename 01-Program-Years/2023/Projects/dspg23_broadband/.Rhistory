page
divs = rvest::html_nodes(page, "div")
result_text = NA
for (i in divs){
subdiv <- rvest::html_nodes(i, 'div')
for (j in subdiv){
print(html_text(j))
}
}
url
address
result_text
index
View(active_set)
# load the data ------------------------------------
subscr_addr <- read.csv('../data_joining/ndproject_subscriber_full_address.csv', header = TRUE, row.names = 1)
buffer_addr <- read_csv('../data_joining/ndproject_bufferzone_full_address.csv', col_types = cols(.default= 'c'))
# rownames(buffer_addr) <- buffer_addr$dpid
subscr_addr[,c('bedrooms', 'bathrooms', 'sqft', 'text')] <- NA
buffer_addr[,c('bedrooms', 'bathrooms', 'sqft', 'text')] <- NA
library(readr)
library(dplyr)
library(data.table)
library(stringr)
library(tidyr)
library(scales)
library(rvest)
# load the data ------------------------------------
subscr_addr <- read.csv('../data_joining/ndproject_subscriber_full_address.csv', header = TRUE, row.names = 1)
buffer_addr <- read_csv('../data_joining/ndproject_bufferzone_full_address.csv', col_types = cols(.default= 'c'))
# rownames(buffer_addr) <- buffer_addr$dpid
subscr_addr[,c('bedrooms', 'bathrooms', 'sqft', 'text', 'source')] <- NA
buffer_addr[,c('bedrooms', 'bathrooms', 'sqft', 'text', 'source')] <- NA
subscr_addr$must_inc_number_address = gsub("^(\\w+)", "\"\\1\"", subscr_addr$full_address)
buffer_addr$must_inc_number_address = gsub("^(\\w+)", "\"\\1\"", buffer_addr$full_address)
set_1<-subscr_addr[1:200,]
#set_2<-bips[67:79,]
#set_3<-bips[79:83,]
active_set<-set_1
google_result_select = function(html_page, domain_keyword, address){
divs = rvest::html_nodes(html_page, "div")
result_text = NA
for (i in divs){
subdiv <- rvest::html_nodes(i, 'div')
for (j in subdiv){
if (grepl(domain_keyword, html_text(j), fixed = TRUE)){
result_text <- html_text(j)
}
if (!is.na(result_text)){
break
}
}
if(!is.na(result_text)){
break
}
}
if(domain_keyword == "realtor" & !is.na(result_text)){
street_number_original = regmatches(address, regexpr("\\b\\d+\\b", address))
street_number_matched = regmatches(result_text, regexpr("\\b\\d+\\b", result_text))
if (street_number_original != street_number_matched){
result_text = NA
}
}
result_text
}
result_text_analyze = function(result_text){
sq_feet <- str_extract(result_text, "(\\d+,)?\\d+\\.?\\d*?(?=\\s(Square Feet))")
if(is.na(sq_feet)){
sq_feet <- str_extract(result_text, "(\\d+,)?\\d+\\.?\\d*?(?=\\s(sqft))")
}
if(is.na(sq_feet)){
sq_feet <- str_extract(result_text, "(\\d+,)?\\d+\\.?\\d*?(?=\\s(square foot))")
}
bed_count <- str_extract(result_text, "\\d+\\.?\\d*?(?=\\s(bed))")
if(is.na(bed_count)){
bed_count <- str_extract(result_text, "\\d+\\.?\\d*?(?=\\s(-bed))")
}
bath_count<- str_extract(result_text, "\\d+\\.?\\d*?(?=\\s(bath))")
if(is.na(bath_count)){
bath_count<- str_extract(result_text, "\\d+\\.?\\d*?(?=\\s(-bath))")
}
data.frame("bedrooms" = bed_count, "bathrooms" = bath_count,  "sqft" = sq_feet, "text" = result_text)
}
source_keywords = c("zillow", "realtor")
for(index in row.names(active_set)){
print(index)
address <- active_set[index, 'must_inc_number_address']
url <- URLencode(paste0("https://www.google.com/search?q=",address))
page <- xml2::read_html(url)
Sys.sleep(3)
best_row = NA
best_source = NA
for (source in source_keywords){
result_text = google_result_select(page, source, address)
result_row = result_text_analyze(result_text)
if (sum(!is.na(result_row)) >  sum(!is.na(best_row))){
best_row = result_row
best_source = source
}
if (sum(is.na(result_row)) == 0){
break
}
}
if (nrow(best_row)){  # filter out empty matches that are just NA
best_row['source'] = best_source
row.names(best_row) = c(index)
active_set[index, c(2,3,4,5,6)] = best_row
}
}
source_keywords = c("zillow", "realtor")
for(index in row.names(active_set)){
print(index)
address <- active_set[index, 'must_inc_number_address']
url <- URLencode(paste0("https://www.google.com/search?q=",address))
page <- xml2::read_html(url)
Sys.sleep(3)
best_row = NA
best_source = NA
for (source in source_keywords){
result_text = google_result_select(page, source, address)
result_row = result_text_analyze(result_text)
if (sum(!is.na(result_row)) >  sum(!is.na(best_row))){
best_row = result_row
best_source = source
}
if (sum(is.na(result_row)) == 0){
break
}
}
if (nrow(best_row)){  # filter out empty matches that are just NA
best_row['source'] = best_source
row.names(best_row) = c(index)
active_set[index, c(2,3,4,5,6)] = best_row
}
}
source_keywords = c("zillow", "realtor")
for(index in row.names(active_set)){
print(index)
address <- active_set[index, 'must_inc_number_address']
url <- URLencode(paste0("https://www.google.com/search?q=",address))
page <- xml2::read_html(url)
Sys.sleep(3)
best_row = NA
best_source = NA
for (source in source_keywords){
result_text = google_result_select(page, source, address)
result_row = result_text_analyze(result_text)
if (sum(!is.na(result_row)) >  sum(!is.na(best_row))){
best_row = result_row
best_source = source
}
if (sum(is.na(result_row)) == 0){
break
}
}
if (nrow(best_row)){  # filter out empty matches that are just NA
best_row['source'] = best_source
row.names(best_row) = c(index)
active_set[index, c(2,3,4,5,6)] = best_row
}
}
source_keywords = c("zillow", "realtor")
for(index in row.names(active_set)){
print(index)
address <- active_set[index, 'must_inc_number_address']
url <- URLencode(paste0("https://www.google.com/search?q=",address))
page <- xml2::read_html(url)
Sys.sleep(3)
best_row = NA
best_source = NA
for (source in source_keywords){
result_text = google_result_select(page, source, address)
result_row = result_text_analyze(result_text)
if (sum(!is.na(result_row)) >  sum(!is.na(best_row))){
best_row = result_row
best_source = source
}
if (sum(is.na(result_row)) == 0){
break
}
}
if (nrow(best_row)){  # filter out empty matches that are just NA
best_row['source'] = best_source
row.names(best_row) = c(index)
active_set[index, c(2,3,4,5,6)] = best_row
}
}
result_text_analyze = function(result_text){
sq_feet <- str_extract(result_text, "(\\d+,)?\\d+\\.?\\d*?(?=\\s(Square Feet))")
if(is.na(sq_feet)){
sq_feet <- str_extract(result_text, "(\\d+,)?\\d+\\.?\\d*?(?=\\s(sqft))")
}
if(is.na(sq_feet)){
sq_feet <- str_extract(result_text, "(\\d+,)?\\d+\\.?\\d*?(?=\\s(square foot))")
}
bed_count <- str_extract(result_text, "\\d+\\.?\\d*?(?=\\s(bed))")
if(is.na(bed_count)){
bed_count <- str_extract(result_text, "\\d+\\.?\\d*?(?=\\s(-bed))")
}
bath_count<- str_extract(result_text, "\\d+\\.?\\d*?(?=\\s(bath))")
if(is.na(bath_count)){
bath_count<- str_extract(result_text, "\\d+\\.?\\d*?(?=\\s(-bath))")
}
data.frame("bedrooms" = bed_count, "bathrooms" = bath_count,  "sqft" = sq_feet, "text" = result_text)
}
source_keywords = c("zillow", "realtor")
for(index in row.names(active_set)){
print(index)
address <- active_set[index, 'must_inc_number_address']
url <- URLencode(paste0("https://www.google.com/search?q=",address))
page <- xml2::read_html(url)
Sys.sleep(3)
best_row = NA
best_source = NA
for (source in source_keywords){
result_text = google_result_select(page, source, address)
result_row = result_text_analyze(result_text)
if (sum(!is.na(result_row)) >  sum(!is.na(best_row))){
best_row = result_row
best_source = source
}
if (sum(is.na(result_row)) == 0){
break
}
}
if (nrow(best_row)){  # filter out empty matches that are just NA
best_row['source'] = best_source
row.names(best_row) = c(index)
active_set[index, c(2,3,4,5,6)] = best_row
}
}
View(active_set)
source_keywords = c("zillow", "realtor")
for(index in row.names(active_set)){
print(index)
address <- active_set[index, 'must_inc_number_address']
url <- URLencode(paste0("https://www.google.com/search?q=",address))
page <- xml2::read_html(url)
Sys.sleep(3)
best_row = NA
best_source = NA
for (source in source_keywords){
result_text = google_result_select(page, source, address)
result_row = result_text_analyze(result_text)
if (sum(!is.na(result_row)) >  sum(!is.na(best_row))){
best_row = result_row
best_source = source
}
if (sum(is.na(result_row)) == 0){
break
}
}
if (nrow(best_row)){  # filter out empty matches that are just NA
best_row['source'] = best_source
row.names(best_row) = c(index)
active_set[index, c(2,3,4,5,6)] = best_row
}
}
nrow(best_row)
if(NULL)
{print(a)}
best_row
is.na(nrow(best_row))
is.null(nrow(best_row))
source_keywords = c("zillow", "realtor")
for(index in row.names(active_set)){
print(index)
tryCatch({
address <- active_set[index, 'must_inc_number_address']
url <- URLencode(paste0("https://www.google.com/search?q=",address))
page <- xml2::read_html(url)
Sys.sleep(3)
best_row = NA
best_source = NA
for (source in source_keywords){
result_text = google_result_select(page, source, address)
result_row = result_text_analyze(result_text)
if (sum(!is.na(result_row)) >  sum(!is.na(best_row))){
best_row = result_row
best_source = source
}
if (sum(is.na(result_row)) == 0){
break
}
}
if (!is.null(nrow(best_row))){  # filter out empty matches that are just NA
best_row['source'] = best_source
row.names(best_row) = c(index)
active_set[index, c(2,3,4,5,6)] = best_row
}
}, error = function(e){
print(e)
next
}
)
}
source_keywords = c("zillow", "realtor")
for(index in row.names(active_set)){
print(index)
tryCatch({
address <- active_set[index, 'must_inc_number_address']
url <- URLencode(paste0("https://www.google.com/search?q=",address))
page <- xml2::read_html(url)
Sys.sleep(3)
best_row = NA
best_source = NA
for (source in source_keywords){
result_text = google_result_select(page, source, address)
result_row = result_text_analyze(result_text)
if (sum(!is.na(result_row)) >  sum(!is.na(best_row))){
best_row = result_row
best_source = source
}
if (sum(is.na(result_row)) == 0){
break
}
}
if (!is.null(nrow(best_row))){  # filter out empty matches that are just NA
best_row['source'] = best_source
row.names(best_row) = c(index)
active_set[index, c(2,3,4,5,6)] = best_row
}
}, error = function(e){
print(e)
}
)
}
View(active_set)
View(active_set)
write.csv(active_set, "subscriber_scrapped_batch_1.csv")
View(active_set)
subscr_addr_scrapped = merge(subscr_addr[c("full_address")], active_set[, -1], by.x = 0, by.y = 0, all.x = TRUE)
View(subscr_addr_scrapped)
write.csv(subscr_addr_scrapped, "subscriber_scrapped_batch_1.csv")
active_set_copy = active_set
active_set = subscr_addr_scrapped[is.na(subscr_addr_scrapped$source)]
active_set = subscr_addr_scrapped[is.na(subscr_addr_scrapped$source),]
View(active_set)
View(subscr_addr)
# active_set_copy = active_set
# active_set = subscr_addr_scrapped[is.na(subscr_addr_scrapped$source),]
active_set = active_set_copy
View(active_set)
subscr_addr_scrapped = merge(subscr_addr[c("full_address", "must_inc_number_address")],
active_set[, -c(1,7)], by.x = 0, by.y = 0, all.x = TRUE)
# active_set_copy = active_set
# active_set = subscr_addr_scrapped[is.na(subscr_addr_scrapped$source),]
# active_set = active_set_copy
View(subscr_addr_scrapped)
# subscr_addr_scrapped = merge(subscr_addr[c("full_address", "must_inc_number_address")],
#                              active_set[, -c(1,7)], by.x = 0, by.y = 0, all.x = TRUE)
active_set_copy = active_set
active_set = subscr_addr_scrapped[is.na(subscr_addr_scrapped$source),]
View(active_set)
source_keywords = c("zillow", "realtor")
for(index in row.names(active_set)){
print(index)
tryCatch({
address <- active_set[index, 'must_inc_number_address']
url <- URLencode(paste0("https://www.google.com/search?q=",address))
page <- xml2::read_html(url)
Sys.sleep(3)
best_row = NA
best_source = NA
for (source in source_keywords){
result_text = google_result_select(page, source, address)
result_row = result_text_analyze(result_text)
if (sum(!is.na(result_row)) >  sum(!is.na(best_row))){
best_row = result_row
best_source = source
}
if (sum(is.na(result_row)) == 0){
break
}
}
if (!is.null(nrow(best_row))){  # filter out empty matches that are just NA
best_row['source'] = best_source
row.names(best_row) = c(index)
active_set[index, c(3,4,5,6,7)] = best_row
}
}, error = function(e){
print(e)
}
)
}
rownames(active_set) = active_set$Row.names
active_set = active_set[, -1]
source_keywords = c("zillow", "realtor")
for(index in row.names(active_set)){
print(index)
tryCatch({
address <- active_set[index, 'must_inc_number_address']
url <- URLencode(paste0("https://www.google.com/search?q=",address))
page <- xml2::read_html(url)
Sys.sleep(3)
best_row = NA
best_source = NA
for (source in source_keywords){
result_text = google_result_select(page, source, address)
result_row = result_text_analyze(result_text)
if (sum(!is.na(result_row)) >  sum(!is.na(best_row))){
best_row = result_row
best_source = source
}
if (sum(is.na(result_row)) == 0){
break
}
}
if (!is.null(nrow(best_row))){  # filter out empty matches that are just NA
best_row['source'] = best_source
row.names(best_row) = c(index)
active_set[index, c(3,4,5,6,7)] = best_row
}
}, error = function(e){
print(e)
}
)
}
write.csv(active_ set, "subscriber_scrapped_batch_2.csv")
write.csv(active_set, "subscriber_scrapped_batch_2.csv")
library(sf)
library(readr)
library(dplyr)
library(progress)
ookla_data_reconnect_2021 <- readRDS('../iaproject/ooka2021_holefree.RDS')
setwd("~/Github/dspg23_broadband/data/reconnect_subscribers")
ookla_data_reconnect_2021 <- readRDS('../iaproject/ooka2021_holefree.RDS')
ookla_data_reconnect_2021 <- ookla_data_reconnect_2021 %>% filter(RUSID == "IA1701-A61")
#write.csv(ookla_data_reconnect_2021, file = "ookla_2021.csv")
# randomly select 20% of the data
#df <- sample_n(ookla_data_reconnect_2021,1000)
#df_list <- split(df, sample(rep(1:5, times = c(200,200,200,200,200))))
df <- ookla_data_reconnect_2021
df_list <- split(df, sample(rep(1:5, times = c(2119, 2119, 2120, 2120, 2220))))
View(df_list)
help(sample)
rep(1:5, times = c(2119, 2119, 2120, 2120, 2220))
df_list <- split(df, sample(rep(1:5, times = c(2119, 2119, 2120, 2120, 2220))))
nrow(df)
length(sample(rep(1:5, times = c(2119, 2119, 2120, 2120, 2220))))
df_list <- split(df, sample(rep(1:5)))
rmse <- data.frame(matrix(0, 5, 10))
rnse
rmse
phi_list <- c(1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000)
test$predicted_speed_1000 <- NA
test$predicted_speed_2000 <- NA
test$predicted_speed_3000 <- NA
test$predicted_speed_4000 <- NA
test$predicted_speed_5000 <- NA
test$predicted_speed_6000 <- NA
test$predicted_speed_7000 <- NA
test$predicted_speed_8000 <- NA
test$predicted_speed_9000 <- NA
test$predicted_speed_10000 <- NA
test <- df_list[[i]]
test$predicted_speed_1000 <- NA
test$predicted_speed_2000 <- NA
test$predicted_speed_3000 <- NA
test$predicted_speed_4000 <- NA
test$predicted_speed_5000 <- NA
test$predicted_speed_6000 <- NA
test$predicted_speed_7000 <- NA
test$predicted_speed_8000 <- NA
test$predicted_speed_9000 <- NA
test$predicted_speed_10000 <- NA
df_list <- split(df, sample(rep(1:5)))
test <- df_list[[i]]
test <- df_list[[1]]
000 <- NA
test$predicted_speed_2000 <- NA
test$predicted_speed_3000 <- NA
test$predicted_speed_4000 <- NA
test$predicted_speed_5000 <- NA
test$predicted_speed_6000 <- NA
test$predicted_speed_7000 <- NA
test$predicted_speed_8000 <- NA
test$predicted_speed_9000 <- NA
test$predicted_speed_10000 <- NA
test
train <- df[-as.numeric(rownames(test)), ]
test_centroids <- st_as_sf(test, coords = tile_centroid_26918, crs = 26918)
for (idx in 1:nrow(test_centroids)) {
print(idx)
dist <- as.numeric( st_distance(test_centroids[idx, ], train) )
for (phi_idx in 1:length(phi_list)) {
phi = phi_list[phi_idx]
weights <- exp(-(dist/phi)^2)
speed <- weighted.mean(train$avg_d_kbps, weights * train$devices)
if(phi == 1000) {
test$predicted_speed_1000[idx] <- speed
} else if(phi == 2000) {
test$predicted_speed_2000[idx] <- speed
}else if(phi == 3000) {
test$predicted_speed_3000[idx] <- speed
}else if(phi == 4000) {
test$predicted_speed_4000[idx] <- speed
}else if(phi == 5000) {
test$predicted_speed_5000[idx] <- speed
}else if(phi == 6000) {
test$predicted_speed_6000[idx] <- speed
}else if(phi == 7000) {
test$predicted_speed_7000[idx] <- speed
}else if(phi == 8000) {
test$predicted_speed_8000[idx] <- speed
}else if(phi == 9000) {
test$predicted_speed_9000[idx] <- speed
}else {
test$predicted_speed_10000[idx] <- speed
}
}
}
