---
title: "R Notebook"
output: html_notebook
---

ver 01: use Zillow to find missing info of properties in BK dataset.
Ver 02 update: add realtor and fastpeoplesearch as additional sources for properties missing info on Zillow.

```{r}
library(readr)
library(dplyr)
library(data.table)
library(stringr)
library(tidyr)
library(scales)
library(rvest)
```

```{r}
# load the data ------------------------------------
subscr_addr <- read.csv('../data_joining/ndproject_subscriber_full_address.csv', header = TRUE, row.names = 1)
buffer_addr <- read_csv('../data_joining/ndproject_bufferzone_full_address.csv', col_types = cols(.default= 'c'))

subscr_addr[,c('bedrooms', 'bathrooms', 'sqft', 'text', 'source')] <- NA
buffer_addr[,c('bedrooms', 'bathrooms', 'sqft', 'text', 'source')] <- NA

subscr_addr$must_inc_number_address = gsub("^(\\w+)", "\"\\1\"", subscr_addr$full_address)
buffer_addr$must_inc_number_address = gsub("^(\\w+)", "\"\\1\"", buffer_addr$full_address)

col_order = c("full_address", "must_inc_number_address", "bedrooms", "bathrooms", "sqft", "text", "source")
subscr_addr = subscr_addr[, col_order]
buffer_addr = buffer_addr[, col_order]
```

```{r}
# set_1<-subscr_addr[1:200,]
#set_2<-bips[67:79,]
#set_3<-bips[79:83,]
# active_set<-set_1

active_set = subscr_addr[is.na(subscr_addr$source), ]
```

```{r}
google_result_select = function(html_page, domain_keyword, address){
  divs = rvest::html_nodes(html_page, "div")
  result_text = NA
  for (i in divs){
    subdiv <- rvest::html_nodes(i, 'div')
    for (j in subdiv){
      if (grepl(domain_keyword, html_text(j), fixed = TRUE)){
        result_text <- html_text(j)
      }
      if (!is.na(result_text)){
        break
      }
    }
    if(!is.na(result_text)){
      break
    }
  }
  
  if(!is.na(result_text)){
    street_number_original = regmatches(address, regexpr("\\b\\d+\\b", address))
    street_number_matched = street_number_original
    
    if(domain_keyword == "realtor" | domain_keyword == "zillow"){
      street_number_matched = regmatches(result_text, regexpr("\\b\\d+\\b", result_text))
    }
    
    if(domain_keyword == "fastpeoplesearch"){
      street_number_matched = gsub(
        "\\D", "",
        regmatches(result_text, regexpr("\\.\\.\\.\\D*\\d+\\b", result_text))
        )
    }
    
    if (is.null(street_number_matched)){
      street_number_matched = ""
    }
    
    if (street_number_original != street_number_matched){
        result_text = NA
    }
    
    result_text
  }
  
  
}
```

```{r}
result_text_analyze = function(text){
  if (identical(text, character(0))) {
    return(data.frame("bedrooms" = NA, "bathrooms" = NA,  "sqft" = NA, "text" = NA))
  }
  
  result_text = str_to_lower(text)
  
  sq_feet <- str_extract(result_text, "(\\d+,)?\\d+\\.?\\d*?(?=\\s(square feet))")
  
  if(is.na(sq_feet)){
    sq_feet <- str_extract(result_text, "(\\d+,)?\\d+\\.?\\d*?(?=\\s(sqft))")
  }
  if(is.na(sq_feet)){
    sq_feet <- str_extract(result_text, "(\\d+,)?\\d+\\.?\\d*?(?=\\s(square foot))")
  }
  if(is.na(sq_feet)){
    sq_feet <- str_extract(result_text, "(\\d+,)?\\d+\\.?\\d*?(?=\\s(sq ft))")
  }
  if(is.na(sq_feet)){
    sq_feet <- str_extract(result_text, "(\\d+,)?\\d+\\.?\\d*?(?=\\s(sq\\. ft\\.))")
  }
  
  bed_count <- str_extract(result_text, "\\d+\\.?\\d*?(?=\\s(bed))")
  if(is.na(bed_count)){
    bed_count <- str_extract(result_text, "\\d+\\.?\\d*?(?=\\s(-bed))")
  }
  
  bath_count<- str_extract(result_text, "\\d+\\.?\\d*?(?=\\s(bath))")
  if(is.na(bath_count)){
    bath_count<- str_extract(result_text, "\\d+\\.?\\d*?(?=\\s(-bath))")
  }
  
  data.frame("bedrooms" = bed_count, "bathrooms" = bath_count,  "sqft" = sq_feet, "text" = text)
}
```

```{r}
source_keywords = c("zillow", "realtor", "fastpeoplesearch")
start = i
for(i in start : nrow(active_set)){
  index = row.names(active_set)[i]
  print(index)
  flag429 = FALSE
  
  tryCatch({
    address <- active_set[index, 'must_inc_number_address']
    url <- URLencode(paste0("https://www.google.com/search?q=",address))
    page <- xml2::read_html(url)
    Sys.sleep(5)
    
    best_row = NA
    best_source = NA
    for (source in source_keywords){
      result_text = google_result_select(page, source, address)
      
      result_row = result_text_analyze(result_text)
      
      if (sum(!is.na(result_row)) >  sum(!is.na(best_row))){
        best_row = result_row
        best_source = source
      }
      if (sum(is.na(result_row)) == 0){
        break
      }
    }
    if (!is.null(nrow(best_row))){  # filter out empty matches that are just NA
      best_row['source'] = best_source
      row.names(best_row) = c(index)
      active_set[index, c(3,4,5,6,7)] = best_row
    }
  },
  error = function(e){
    print(e)
    
    if(grepl("HTTP error 429", e, fixed = TRUE)){
      flag429 <<- TRUE  # global assignment
      print("Too frequent requests, change IP or retry later")
      
    }
  })
  if (flag429) {
    break
  }
  
}
```

```{r}
subscr_addr = active_set
write.csv(subscr_addr, "subscriber_scrapped.csv")
# subscr_addr = read.csv("subscriber_scrapped.csv")
print(sum(is.na(subscr_addr$sqft)))
print(sum(is.na(subscr_addr$bedrooms)))
print(sum(is.na(subscr_addr$bathrooms)))
```

